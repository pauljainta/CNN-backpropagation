{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Backprop.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNgJrWmjjRe/FrLoUGtcDWJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pauljainta/CNN-backpropagation/blob/main/CNN_Backprop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 198,
      "metadata": {
        "id": "S6QTBZNebEW7"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from sklearn.metrics import f1_score , accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOAD DATA**"
      ],
      "metadata": {
        "id": "9Ql-24Zjb_UG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_mnist, y_train_mnist), (x_test_mnist, y_test_mnist) = datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "LroboPpLb-RP"
      },
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# y_train_mnist = y_train_mnist.reshape(-1 , 1)\n",
        "# y_test_mnist = y_test_mnist.reshape(-1 , 1)\n",
        "\n",
        "\n",
        "print(x_train_mnist.shape)\n",
        "print(y_train_mnist.shape)\n",
        "print(y_test_mnist.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRI1R5hQcqvB",
        "outputId": "8010d826-aea2-45d0-c588-c7171d319aca"
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.ylabel(\"Image\")\n",
        "plt.imshow(x_train_mnist[10, :], cmap='gray')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "nzPt0JKterSZ",
        "outputId": "c2eca446-b939-4324-bb40-2cdf3bfebe30"
      },
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f18469601d0>"
            ]
          },
          "metadata": {},
          "execution_count": 201
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(x_train_mnist)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnaeaR_2jmic",
        "outputId": "16f97a66-657e-4321-baf3-fba4c056b945"
      },
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 202
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_mnist = x_train_mnist[ :,np.newaxis]\n",
        "print(x_train_mnist.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peYrqwcmjrj6",
        "outputId": "b029cbf7-54f7-459e-8553-a801edeb0f1d"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 1, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test_mnist = x_test_mnist[ :,np.newaxis]\n",
        "print(x_test_mnist.shape)\n",
        "print(y_test_mnist.shape)\n",
        "size_of_each_batch = 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz6PR8TCt4_q",
        "outputId": "f6027295-570b-4791-975b-0e725b9f39c9"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 1, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train_cifer, y_train_cifer), (x_test_cifer, y_test_cifer) = datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "JTmW2TwPvmQJ"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_cifer.shape)\n",
        "print(y_train_cifer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oor7Far3v3Zw",
        "outputId": "0e38ca63-8b16-4245-ba72-ef21f5056025"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_cifer = np.transpose(x_train_cifer , (0 , 3 ,1 ,2 ))\n",
        "\n",
        "x_test_cifer = np.transpose(x_test_cifer , (0 , 3 ,1 ,2 ))\n",
        "\n"
      ],
      "metadata": {
        "id": "0SsZ1bPIxrDy"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train_cifer.shape)\n",
        "print(y_train_cifer.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-G_nVIC7xSsQ",
        "outputId": "215c7b22-9469-41d8-dac8-8e45ca97e972"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 3, 32, 32)\n",
            "(50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Batch_Creation(x , y):\n",
        "  \n",
        "    global size_of_each_batch\n",
        "\n",
        "    total_number_of_batches = int(math.floor(y.shape[0] / size_of_each_batch))\n",
        "    list_of_mini_batches = []\n",
        "\n",
        "    for i in range(total_number_of_batches):\n",
        "      if y.shape[0] % size_of_each_batch != 0 and i == total_number_of_batches-1 :\n",
        "        list_of_mini_batches.append((x[i*size_of_each_batch:, :] , y[i*size_of_each_batch:] ))\n",
        "\n",
        "      list_of_mini_batches.append((x[i*size_of_each_batch:(i+1)*size_of_each_batch , :] , y[i*size_of_each_batch:(i+1)*size_of_each_batch]))\n",
        "   \n",
        "    return list_of_mini_batches\n"
      ],
      "metadata": {
        "id": "6LEtKzgWbWlI"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size_of_each_batch = 128\n",
        "# batches = Batch_Creation(x_train_mnist , y_train_mnist)\n",
        "# print(len(batches))\n",
        "# print(batches[0][1].shape)"
      ],
      "metadata": {
        "id": "hBta9-0SejXr"
      },
      "execution_count": 210,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def zero_padding(x , padding):\n",
        "  return np.pad(x, ((0, 0), (0, 0), (padding, padding), (padding, padding)), mode='constant')"
      ],
      "metadata": {
        "id": "mwM0FHHQhMgS"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "x = np.random.randn(4, 3, 3, 2)\n",
        "x_pad = zero_padding(x, 2)\n",
        "print (\"x.shape =\\n\", x.shape)\n",
        "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
        "print (\"x[1,1] =\\n\", x[1,1])\n",
        "print (\"x_pad[1,1] =\\n\", x_pad[1,1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9qHV78Fhn43",
        "outputId": "a8c04276-78ac-494a-f3d7-e27d81a13bcb"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.shape =\n",
            " (4, 3, 3, 2)\n",
            "x_pad.shape =\n",
            " (4, 3, 7, 6)\n",
            "x[1,1] =\n",
            " [[ 0.90085595 -0.68372786]\n",
            " [-0.12289023 -0.93576943]\n",
            " [-0.26788808  0.53035547]]\n",
            "x_pad[1,1] =\n",
            " [[ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.90085595 -0.68372786  0.          0.        ]\n",
            " [ 0.          0.         -0.12289023 -0.93576943  0.          0.        ]\n",
            " [ 0.          0.         -0.26788808  0.53035547  0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]\n",
            " [ 0.          0.          0.          0.          0.          0.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_layer_forward(stride , padding , w , b , x):\n",
        "\n",
        "    padded_x = zero_padding(x , padding)\n",
        "\n",
        "    N = x.shape[0]\n",
        "    C = x.shape[1]\n",
        "    H = x.shape[2]\n",
        "    W = x.shape[3]\n",
        "\n",
        "    F = w.shape[0]\n",
        "    FH = w.shape[2]\n",
        "    FW = w.shape[3]\n",
        "\n",
        "    W2 = int((W - FW + 2*padding)/stride + 1)\n",
        "    H2 = int((H - FH + 2*padding)/stride + 1)\n",
        "\n",
        "    all_selected_column_x = np.zeros((C * FH * FW, H2 * W2))\n",
        "    all_selected_row_w = w.reshape(F, C * FH * FW)\n",
        "\n",
        "    output = np.zeros((N, F, H2, W2))\n",
        "\n",
        "\n",
        "    for i in range(N):\n",
        "        column = 0\n",
        "        for j in range(0, padded_x.shape[2] + 1 - FH, stride):\n",
        "            for k in range(0, padded_x.shape[3]  + 1 - FW, stride):\n",
        "                temp = padded_x[i, :, j:j+FH, k:k+FW]\n",
        "                all_selected_column_x[:, column] = temp.reshape(C * FH * FW)\n",
        "                column += 1\n",
        "        \n",
        "        current_unit_output = np.dot(all_selected_row_w, all_selected_column_x) + (b.reshape(-1, 1))\n",
        "        output[i, :, :, :] = current_unit_output.reshape(F, H2, W2)\n",
        "\n",
        "  \n",
        "    return output, (stride, padding , w , b , x)\n"
      ],
      "metadata": {
        "id": "AP_OCVEciATJ"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# w1 = np.random.normal(0.0, 0.01, (6, 1, 5, 5))\n",
        "# b1 = np.zeros((6, ))\n",
        "\n",
        "# out1 , cache1 = convolutional_layer_forward(1 , 2 , w1 , b1 , batches[0][0])\n",
        "\n",
        "# print(out1.shape)"
      ],
      "metadata": {
        "id": "RQnQq1xtpNq6"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_forward(x):\n",
        "  return np.maximum(0 , x) , x"
      ],
      "metadata": {
        "id": "hXUD_fImx01E"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out2 , cache2 = relu_forward(out1)\n",
        "\n",
        "# print(out2[0])"
      ],
      "metadata": {
        "id": "pyzWsRndyRuX"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pooling_layer_forward(stride , filter_dimension , x):\n",
        "  N = x.shape[0]\n",
        "  C = x.shape[1]\n",
        "  H = x.shape[2]\n",
        "  W = x.shape[3]\n",
        "\n",
        "  H2 = math.floor((H - filter_dimension) / stride) + 1\n",
        "  W2 = math.floor((W - filter_dimension) / stride) + 1\n",
        "\n",
        "  output = np.zeros((N, C, H2, W2))\n",
        "\n",
        "  for i in range(N):\n",
        "      current_unit_output = np.zeros((C, H2* W2))\n",
        "      column = 0\n",
        "      for j in range(0, H - filter_dimension + 1, stride):\n",
        "          for k in range(0, W - filter_dimension + 1, stride):\n",
        "              selected_block_of_x = x[i, :, j:j+filter_dimension, k:k+filter_dimension]\n",
        "              selected_block_of_x = selected_block_of_x.reshape(C, filter_dimension ** 2)\n",
        "\n",
        "              max_value_from_current_block = np.max(selected_block_of_x, axis=1)\n",
        "              current_unit_output[:, column] = max_value_from_current_block\n",
        "\n",
        "              column += 1\n",
        "              \n",
        "      output[i, :, :, :] = current_unit_output.reshape(C, H2 , W2)\n",
        "\n",
        "  return output, (filter_dimension , stride , x) \n"
      ],
      "metadata": {
        "id": "hUH7Ff5WsC_P"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# out3 , cache3 = pooling_layer_forward(2 , 2 , out2)\n",
        "\n",
        "# print(out3.shape)\n",
        "# print(out3[0])"
      ],
      "metadata": {
        "id": "ugdwAWpuwAuq"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fc_layer_forward(x, w, b):\n",
        "  N = x.shape[0]\n",
        "  C = x.shape[1]\n",
        "  H = x.shape[2]\n",
        "  W = x.shape[3]\n",
        " \n",
        "  \n",
        "  return np.dot(x.reshape(N , C * H * W) , w) + b , (w , b , x) "
      ],
      "metadata": {
        "id": "EL__PmvC2wqS"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# w2 = np.random.normal(0.0, 0.01, (6*14*14, 10))\n",
        "# b2 = np.zeros((10, ))\n",
        "\n",
        "# out4 , cache4 = fc_layer_forward(out3 , w2 , b2)\n",
        "# print(out4.shape)\n"
      ],
      "metadata": {
        "id": "bsAW1yiF6Mno"
      },
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_activation(predict , y_hat , y):\n",
        "  y_hat = y_hat - np.max(y_hat, axis=1, keepdims=True)\n",
        "  \n",
        "  probs = np.exp(y_hat) / np.sum(np.exp(y_hat) , axis = 1 , keepdims=True)\n",
        "\n",
        "  if predict == True:\n",
        "    return probs\n",
        "\n",
        "  No_of_samples = probs.shape[0]\n",
        "    \n",
        "  average_loss = np.sum(np.log(probs[np.arange(No_of_samples), y])) / No_of_samples\n",
        "\n",
        "  average_loss = average_loss * (-1)\n",
        "\n",
        "  derivative = np.copy(probs)\n",
        "  derivative[np.arange(No_of_samples), y] -= 1\n",
        "  # derivative = probs[np.arange(No_of_samples), y] - 1\n",
        "\n",
        "  return probs ,  average_loss, derivative / No_of_samples "
      ],
      "metadata": {
        "id": "CjJlq-zc759C"
      },
      "execution_count": 221,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# probs , average_loss , derivative = softmax_activation(False , out4 , batches[0][1])\n",
        "\n",
        "# print(probs[0])\n",
        "# print(derivative[0])\n",
        "# print(average_loss)"
      ],
      "metadata": {
        "id": "vRYLA0t2_mo4"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fc_layer_backward(dout, cache):\n",
        "    w = cache[0]\n",
        "    x = cache[2]\n",
        "\n",
        "    dx = np.dot(dout, w.T).reshape(x.shape)\n",
        "    dw = np.dot(x.reshape(x.shape[0], -1).T, dout)\n",
        "    db = np.sum(dout.T, axis=1)\n",
        "\n",
        "    return dw, db , dx"
      ],
      "metadata": {
        "id": "Uothm4JFREM3"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dw4 , db4 , dx4 = fc_layer_backward(out4 , cache4)\n",
        "# print(dw4.shape)\n",
        "# print(db4.shape)\n",
        "# print(dx4.shape)"
      ],
      "metadata": {
        "id": "edWCIO1xUQB7"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pooling_layer_backward(dout, cache):\n",
        "  \n",
        "  filter_dimension , stride , x = cache \n",
        "  N = x.shape[0]\n",
        "  C = x.shape[1]\n",
        "  H = x.shape[2]\n",
        "  W = x.shape[3]\n",
        "  H2 = dout.shape[2]\n",
        "  W2 = dout.shape[3]\n",
        "\n",
        "  dx = np.zeros_like(x)\n",
        "\n",
        "  for i in range(N):\n",
        "      current_unit_output = dout[i, :].reshape(C, H2 * W2)\n",
        "      column = 0\n",
        "      for j in range(0, H + 1 - filter_dimension, stride):\n",
        "          for k in range(0, W + 1 - filter_dimension, stride): \n",
        "              selected_block_of_x = x[i, :, j:j+filter_dimension, k:k+filter_dimension]\n",
        "              selected_block_of_x = selected_block_of_x.reshape(C, filter_dimension ** 2)\n",
        "\n",
        "              index_of_max_value_from_current_block = np.argmax(selected_block_of_x, axis=1)\n",
        "\n",
        "              current_unit_output_block = current_unit_output[:, column]\n",
        "\n",
        "              selected_block_of_x_dx_pooling = np.zeros_like(selected_block_of_x)\n",
        "              selected_block_of_x_dx_pooling[np.arange(C), index_of_max_value_from_current_block] = current_unit_output_block\n",
        "\n",
        "              dx[i, :, j:j+filter_dimension, k:k+filter_dimension] = selected_block_of_x_dx_pooling.reshape(C, filter_dimension, filter_dimension)\n",
        "\n",
        "              column += 1\n",
        "  \n",
        "  return dx"
      ],
      "metadata": {
        "id": "xhDC0KfYU2se"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dx3 = pooling_layer_backward(dx4 , cache3)\n",
        "\n",
        "# print(dx3.shape)"
      ],
      "metadata": {
        "id": "u_Tdm_C-bimr"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def relu_backward(dout, cache):\n",
        "   \n",
        "    dx = dout * (cache > 0)\n",
        "\n",
        "    return dx"
      ],
      "metadata": {
        "id": "EcAAdQtMcKO2"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dx2 = relu_backward(dx3 , cache2)\n",
        "\n",
        "# print(dx2.shape)"
      ],
      "metadata": {
        "id": "y9NrFYf6ebKK"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convolutional_layer_backward(dout, cache):\n",
        "\n",
        "  H2 = dout.shape[2]\n",
        "  W2 = dout.shape[3]\n",
        "  stride, pad , w , b , x = cache \n",
        "  N = x.shape[0]\n",
        "  C = x.shape[1]\n",
        "  F = w.shape[0]\n",
        "  FH = w.shape[2]\n",
        "  FW = w.shape[3]\n",
        "\n",
        "\n",
        "  dw = np.zeros_like(w)\n",
        "  db = np.zeros_like(b) \n",
        "  dx = np.zeros_like(x)\n",
        "\n",
        "  padded_x = zero_padding(x , pad)\n",
        "\n",
        "  all_selected_row_w= w.reshape(F, C * FH * FW)\n",
        "  all_selected_col_x = np.zeros((C * FH * FW, H2 * W2))\n",
        "\n",
        "  for i in range(N):\n",
        "      current_padded_dx = np.zeros(padded_x.shape[1:])\n",
        "      column = 0\n",
        "      current_unit_dout = dout[i, :, :, :].reshape(F, H2 * W2)\n",
        "      current_unit_output = np.dot(all_selected_row_w.T, current_unit_dout)\n",
        "      for j in range(0, padded_x.shape[2]- FH + 1, stride):\n",
        "          for k in range(0, padded_x.shape[3] - FW + 1, stride):\n",
        "            all_selected_col_x[:, column] = padded_x[i, :, j:j+FH, k:k+FW].reshape(C * FH * FW) \n",
        "            current_padded_dx[:, j:j+FH, k:k+FW] += current_unit_output[:, column].reshape(C, FH, FW)\n",
        "            column += 1\n",
        "\n",
        "      if pad == 0:\n",
        "        dx[i] = current_padded_dx\n",
        "      else:\n",
        "        dx[i] = current_padded_dx[:, pad:-pad, pad:-pad]\n",
        "      \n",
        "      db += np.sum(current_unit_dout, axis=1)\n",
        "      temp_dot = np.dot(current_unit_dout, all_selected_col_x.T) \n",
        "      temp_dot = temp_dot.reshape(F , C , FH , FW)\n",
        "\n",
        "      dw += temp_dot\n",
        "      \n",
        "\n",
        "  return  dw, db , dx"
      ],
      "metadata": {
        "id": "BVwr-jo2gAU1"
      },
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dw1 , db1 , dx1 = convolutional_layer_backward(dx2 , cache1)\n",
        "\n",
        "# print(dw1.shape)"
      ],
      "metadata": {
        "id": "mmtt0noTJsg-"
      },
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_weights(W , B , DW , DB , alpha):\n",
        "  for i in range(len(W)):\n",
        "    W[i] = W[i] - (alpha * DW[i])\n",
        "\n",
        "  for i in range(len(B)):\n",
        "    B[i] = B[i] - (alpha * DB[i])\n",
        "\n",
        "  return W , B\n",
        "\n"
      ],
      "metadata": {
        "id": "8OqAKBUJXfgm"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Model(batches , epoch , alpha):\n",
        "\n",
        "  global x_test_mnist \n",
        "  global y_test_mnist\n",
        "\n",
        "  global x_test_cifer \n",
        "  global y_test_cifer\n",
        "\n",
        "  w1 = np.random.normal(0.0, 0.01, (6, 1, 5, 5))\n",
        "  b1 = np.zeros((6, ))\n",
        "\n",
        "  w2 = np.random.normal(0.0, 0.01, (12, 6, 5, 5))\n",
        "  b2 = np.zeros((12, ))\n",
        "\n",
        "  w3 = np.random.normal(0.0, 0.01, (100, 12, 5, 5))\n",
        "  b3 = np.zeros((100, ))\n",
        "\n",
        "  w4 = np.random.normal(0.0, 0.01, (100*1*1, 10))\n",
        "  b4 = np.zeros((10,))\n",
        "\n",
        "  # w1 = np.random.normal(0.0, 0.01, (6, 3, 5, 5))\n",
        "  # b1 = np.zeros((6, ))\n",
        "\n",
        "  # w2 = np.random.normal(0.0, 0.01, (12, 6, 5, 5))\n",
        "  # b2 = np.zeros((12, ))\n",
        "\n",
        "  # w3 = np.random.normal(0.0, 0.01, (100, 12, 5, 5))\n",
        "  # b3 = np.zeros((100, ))\n",
        "\n",
        "  # w4 = np.random.normal(0.0, 0.01, (100*2*2, 10))\n",
        "  # b4 = np.zeros((10,))\n",
        "\n",
        "  W = [w1 , w2 , w3 , w4]\n",
        "  B = [b1 , b2 ,b3 , b4]\n",
        "\n",
        "\n",
        "\n",
        "  for _ in range(epoch):\n",
        "\n",
        "    for batch in batches:\n",
        "      x , y = batch \n",
        "  # forward prop\n",
        "      out1 , cache1 = convolutional_layer_forward(1 , 2 , w1 , b1 , x)\n",
        "\n",
        "      out2 , cache2 = relu_forward(out1)\n",
        "\n",
        "      out3 , cache3 = pooling_layer_forward(2 , 2 , out2)\n",
        "\n",
        "      out4 , cache4 = convolutional_layer_forward(1 , 0 , w2 , b2 , out3)\n",
        "\n",
        "      out5 , cache5 = relu_forward(out4)\n",
        "\n",
        "      out6 , cache6 = pooling_layer_forward(2 , 2 , out5)\n",
        "\n",
        "      out7 , cache7 = convolutional_layer_forward(1 , 0 , w3 , b3 , out6)\n",
        "\n",
        "      out8 , cache8 = relu_forward(out7)\n",
        "\n",
        "      out9 , cache9 = fc_layer_forward(out8 , w4 , b4)\n",
        "  # loss calculation\n",
        "      probs , loss , derivative = softmax_activation(False , out9 , y)\n",
        "  # back prop\n",
        "      dw4 , db4 , dout9 = fc_layer_backward(derivative , cache9)\n",
        "      dout8 = relu_backward(dout9 , cache8)\n",
        "      dw3 , db3 , dout7 = convolutional_layer_backward(dout8 , cache7)\n",
        "\n",
        "      dout6 = pooling_layer_backward(dout7 , cache6)\n",
        "      dout5 = relu_backward(dout6 , cache5)\n",
        "      dw2 , db2 , dout4 = convolutional_layer_backward(dout5 , cache4)\n",
        "\n",
        "      dout3 = pooling_layer_backward(dout4 , cache3)\n",
        "      dout2 = relu_backward(dout3 , cache2)\n",
        "      dw1 , db1 , dout1 = convolutional_layer_backward(dout2 , cache1)\n",
        "\n",
        "      DW = [dw1 , dw2 , dw3 , dw4]\n",
        "      DB = [db1 , db2 ,db3 , db4]\n",
        "\n",
        "      [w1 , w2 , w3 , w4] , [b1 , b2 ,b3 , b4]  = update_weights(W , B , DW , DB , alpha)\n",
        "    \n",
        "    _ , accuracy , macro_f1_score = Predict([w1 , w2 , w3 , w4] , [b1 , b2 ,b3 , b4] , x_test_mnist , y_test_mnist)\n",
        "\n",
        "    print(\"Epoch:\" + str(epoch+1) + \"Accuracy:\" + str(accuracy) + \" Macro F1 Score :\" + str(macro_f1_score))\n",
        "\n",
        "\n",
        "  return [w1 , w2 , w3 , w4] , [b1 , b2 ,b3 , b4]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jkZlzClnM4Rc"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Predict(W  , B , x , y):\n",
        "  [w1 , w2 , w3 , w4] = W\n",
        "  [b1 , b2 , b3 , b4] = B\n",
        "\n",
        "  out1 , cache1 = convolutional_layer_forward(1 , 2 , w1 , b1 , x)\n",
        "\n",
        "  out2 , cache2 = relu_forward(out1)\n",
        "\n",
        "  out3 , cache3 = pooling_layer_forward(2 , 2 , out2)\n",
        "\n",
        "  out4 , cache4 = convolutional_layer_forward(1 , 0 , w2 , b2 , out3)\n",
        "\n",
        "  out5 , cache5 = relu_forward(out4)\n",
        "\n",
        "  out6 , cache6 = pooling_layer_forward(2 , 2 , out5)\n",
        "\n",
        "  out7 , cache7 = convolutional_layer_forward(1 , 0 , w3 , b3 , out6)\n",
        "\n",
        "  out8 , cache8 = relu_forward(out7)\n",
        "\n",
        "  out9 , cache9 = fc_layer_forward(out8 , w4 , b4)\n",
        "# loss calculation\n",
        "  probs  = softmax_activation(True , out9 , y)\n",
        "\n",
        "  predictions = np.argmax(probs, axis=1)\n",
        "  accuracy = accuracy_score(y , predictions)\n",
        "  macro_f1_score = f1_score(y , predictions , average='macro' , zero_division = 1)\n",
        "\n",
        "  return predictions , accuracy , macro_f1_score \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rMfs7dgGcWRt"
      },
      "execution_count": 233,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "size_of_each_batch = 32\n",
        "batches = Batch_Creation(x_train_mnist , y_train_mnist)\n",
        "# print(len(batches))\n",
        "# print(batches[0][1].shape)\n",
        "\n",
        "W , B = Train_Model(batches , 5 , 0.01)\n",
        "\n",
        "# predictions , accuracy = Predict(W , B , x_test_mnist , y_test_mnist)\n",
        "# print(predictions)\n",
        "# print(accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "M6T0vIjsV0MG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# size_of_each_batch = 32\n",
        "# batches = Batch_Creation(x_train_cifer , y_train_cifer)\n",
        "# # print(len(batches))\n",
        "# print(batches[0][1].shape)\n",
        "\n",
        "# W , B = Train_Model(batches , 5 , 0.01)\n",
        "\n",
        "# predictions , accuracy = Predict(W , B , x_test_cifer , y_test_cifer)\n",
        "# print(predictions)\n",
        "# print(accuracy)"
      ],
      "metadata": {
        "id": "Sym12J_QyPZ5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}